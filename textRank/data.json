{"id": 777, "text": " Clustering algorithms examine data to find groups of items that are similar. For example, an insurance company might group customers according to income, age, types of policy purchased or prior claims experience. In a fault diagnosis application, electrical faults might be grouped according to the values of certain key variables.\n Data clustering is a method in which we make cluster of objects that are somehow similar in characteristics. The criterion for checking the similarity is implementation dependent. Clustering techniques apply when there is no class to be predicted but rather when the instances are to be decided into natural groups. These clusters presumably reflect some mechanism at work in the domain from which instances are drawn, a mechanism that causes some instances to bear a stronger resemblance to each other than they do to the remaining instances. Clustering naturally required different techniques to the classification and association learning methods that we have considered so far. As we saw in Section 3.6, there are different ways in which the result of clustering can be expressed. The groups that are identified may be exclusive: any instance belongs in only one group. Or they may be overlapping: an instance may fall into several groups. Ot they may be probabilistic: an instance belongs to each group with a certain probability. Or they may be hierarchical: a rough division of instances into groups at the top level and each group refined further - perhaps all the way down to individual instances. Really, the choice among these possibilities should be dictated by the nature of the mechanisms that are thought to underlie the particular clustering phenomenon. However, because these mechanisms are rarely known - the very existence of clusters is, after all, something that we\u2019re trying to discover - and for pragmatic reasons too, the choice is usually dictated by the clustering tools that are available. Clustering techniques consider data tuples as objects. They partition the objects into groups, or clusters, so that objects within a cluster are \u201csimilar\u201d to one another and \u201cdis- similar\u201d to objects in other clusters. Similarity is commonly defined in terms of how \u201cclose\u201d the objects are in space, based on a distance function. The \u201cquality\u201d of a cluster may be represented by its diameter, the maximum distance between any two objects in the cluster. Centroid distance is an alternative measure of cluster quality and is defined as the average distance of each cluster object from the cluster centroid (denoting the \u201caverage object,\u201d or average point in space for the cluster). Figure 3.3 showed a 2-D plot of customer data with respect to customer locations in a city. Three data clusters are visible.\nIn data reduction, the cluster representations of the data are used to replace the actual data. The effectiveness of this technique depends on the data\u2019s nature. It is much more effective for data that can be organized into distinct clusters than for smeared data. Clustering can be considered the most important unsupervised learning problem; so, as every other problem of this kind, it deals with finding a structure in a collection of unlabeled data.\nA loose definition of clustering could be \u201cthe process of organizing objects into groups whose members are similar in some way\u201d.\nA cluster is therefore a collection of objects which are \u201csimilar\u201d between them and are \u201cdissimilar\u201d to the objects belonging to other clusters. Clustering can be defined as the process of grouping a collection of N patterns into distinct segments or clusters based on a suitable notion of closeness or similarity among these patterns. Good clusters show high similarity within a group and low similarity between patterns belonging to two different groups. For applications such as customer or product segmentation, clustering is the primary goal. But more often it is a crucial intermediate step needed for further data analysis, a view underscored by the placement of the cluster utility in the \"exploration\" stage in Enterprise Miner, a leading data mining software from SAS institute. Clustering is the grouping of a particular set of objects based on their characteristics, aggregating them according to their similarities. Regarding to data mining, this metodology partitions the data implementing a specific join algorithm, most suitable for the desired information analysis. Clustering is the process of making a group of abstract objects into classes of similar objects. Cluster analysis groups data objects based only on information found in the data that describes the objects and their relationships. The goal is that the objects within a group be similar (or related) to one another and different from (or unrelated to) the objects in other groups. The greater the similarity (or homogeneity) within a group and the greater the difference between groups, the better or more distinct the clustering. Clustering analysis finds clusters of data objects that are similar in some sense to one another. The members of a cluster are more like each other than they are like members of other clusters. The goal of clustering analysis is to find high-quality clusters such that the inter-cluster similarity is low and the intra-cluster similarity is high. Cluster Analysis technique as a field grew very quickly with the goal of grouping data objects, based on information found in data and describing the relationships inside the data. The purpose is to separate the objects into groups, with the objects related (similar) together and unrelated with another group of objects. It is being applied in variety of science disciplines and has been studied in myriad of expert research communities such as machine learning, statistic, optimization and computational geometry."}